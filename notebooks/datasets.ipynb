{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bella.helper import read_config, full_path\n",
    "from bella.parsers import semeval_14, dong, election\n",
    "from bella.data_types import TargetCollection\n",
    "from bella.tokenisers import ark_twokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the datasets\n",
    "semeval_14_rest_train = semeval_14(full_path(read_config('semeval_2014_rest_train')))\n",
    "semeval_14_lap_train = semeval_14(full_path(read_config('semeval_2014_lap_train')))\n",
    "semeval_14_rest_test = semeval_14(full_path(read_config('semeval_2014_rest_test')))\n",
    "semeval_14_lap_test = semeval_14(full_path(read_config('semeval_2014_lap_test')))\n",
    "dong_train = dong(full_path(read_config('dong_twit_train_data')))\n",
    "dong_test = dong(full_path(read_config('dong_twit_test_data')))\n",
    "election_train, election_test = election(full_path(read_config('election_folder_dir')))\n",
    "mitchel_train = semeval_14(full_path(read_config('mitchel_train')))\n",
    "mitchel_test = semeval_14(full_path(read_config('mitchel_test')))\n",
    "\n",
    "youtubean = semeval_14(full_path(read_config('youtubean')))\n",
    "semeval_14_rest = TargetCollection.combine_collections(semeval_14_rest_train,\n",
    "                                                           semeval_14_rest_test)\n",
    "semeval_14_laptop = TargetCollection.combine_collections(semeval_14_lap_train,\n",
    "                                                         semeval_14_lap_test)\n",
    "dong = TargetCollection.combine_collections(dong_train, dong_test)\n",
    "election = TargetCollection.combine_collections(election_train, election_test)\n",
    "mitchel = TargetCollection.combine_collections(mitchel_train, mitchel_test)\n",
    "# Combine all of the product reviews\n",
    "datasets = {'SemEval 14 Laptop' : semeval_14_laptop, 'SemEval 14 Resturant' : semeval_14_rest,\n",
    "            'Mitchel' : mitchel, 'Dong Twitter' : dong, \n",
    "            'Election Twitter' : election, 'YouTuBean' : youtubean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "This notebook will describe the different datasets that have been used as well as the statistics of these datasets. The datasets used are the following:\n",
    "1. [Dong et al.](https://aclanthology.coli.uni-saarland.de/papers/P14-2009/p14-2009) [Twitter dataset](https://github.com/bluemonk482/tdparse/tree/master/data/lidong) NOTE that the dataset does not link to the paper as the dataset released from the paper has already been pre-processed where as this dataset has not.\n",
    "2. [SemEval 2014 Resturant dataset](http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools). We used Train dataset version 2 and the test dataset. This dataset contains 4 sentiment values; 1. Positive, 2. Neutral, 3. Negative, and 4. Conflict but we are only going to use the first 3 to make it comparable to the other datasets and the fact that the conflict label only has 91 instances in the training set and 14 in the test set.\n",
    "3. [SemEval 2014 Laptop dataset](http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools). We used Train dataset version2 and the test dataset. This dataset contains 4 sentiment values; 1. Positive, 2. Neutral, 3. Negative, and 4. Conflict but we are only going to use the first 3 to make it comparable to the other datasets and the fact that the conflict label only has 45 instances in the training set and 16 in the test set.\n",
    "4. [Election dataset](https://figshare.com/articles/EACL_2017_-_Multi-target_UK_election_Twitter_sentiment_corpus/4479563/1)\n",
    "5. [Youtubean dataset](https://github.com/epochx/opinatt/blob/master/samsung_galaxy_s5.xml) [by Marrese-Taylor et al.](https://www.aclweb.org/anthology/W17-5213) - Dataset of 7 youtube reviews of the Samsung Galaxy S5. The text are the closed captions of the videos where the captions were provided by the authors and not automatically generated. The dataset does contain 7 conflict labels which in the original paper were matched to neutral labels however in our experiments we remove these labels thus that statistics we present here are slightly different to those in the original paper when describing the dataset. However if you parse the dataset and include the conflicts then the statistics will match the original paper. (To parse the dataset with conflicts add conflict=True parameter to *semeval_14* function)\n",
    "6. [Mitchel dataset](http://www.m-mitchell.com/code/MitchellEtAl-13-OpenSentiment.tgz) which was released with this [paper](https://www.aclweb.org/anthology/D13-1171). The dataset is of Tweets where the targets are named entities specifically either orgainsations or persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Medium</th>\n",
       "      <th>No. Targets (Dataset Size)</th>\n",
       "      <th>No. Senti Labels</th>\n",
       "      <th>Mean Targets per Sent</th>\n",
       "      <th>No Unique Targets</th>\n",
       "      <th>% Targets with 1 Sentiment per Sentence</th>\n",
       "      <th>% Targets with 2 Sentiment per Sentence</th>\n",
       "      <th>% Targets with 3 Sentiment per Sentence</th>\n",
       "      <th>Avg sentence length per target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>Laptop</td>\n",
       "      <td>Review</td>\n",
       "      <td>Written</td>\n",
       "      <td>2951</td>\n",
       "      <td>3</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1295</td>\n",
       "      <td>81.09</td>\n",
       "      <td>17.62</td>\n",
       "      <td>1.29</td>\n",
       "      <td>18.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Resturant</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Review</td>\n",
       "      <td>Written</td>\n",
       "      <td>4722</td>\n",
       "      <td>3</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1630</td>\n",
       "      <td>75.26</td>\n",
       "      <td>22.94</td>\n",
       "      <td>1.80</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Written</td>\n",
       "      <td>3288</td>\n",
       "      <td>3</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2507</td>\n",
       "      <td>90.48</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>18.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>General</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Written</td>\n",
       "      <td>6940</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>145</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Written</td>\n",
       "      <td>11899</td>\n",
       "      <td>3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2190</td>\n",
       "      <td>44.50</td>\n",
       "      <td>46.72</td>\n",
       "      <td>8.78</td>\n",
       "      <td>21.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>Mobile Phones</td>\n",
       "      <td>Review</td>\n",
       "      <td>Spoken</td>\n",
       "      <td>798</td>\n",
       "      <td>3</td>\n",
       "      <td>2.07</td>\n",
       "      <td>522</td>\n",
       "      <td>81.45</td>\n",
       "      <td>18.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>22.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Domain          Type   Medium  \\\n",
       "SemEval 14 Laptop            Laptop        Review  Written   \n",
       "SemEval 14 Resturant     Restaurant        Review  Written   \n",
       "Mitchel                     Unknown  Social Media  Written   \n",
       "Dong Twitter                General  Social Media  Written   \n",
       "Election Twitter           Politics  Social Media  Written   \n",
       "YouTuBean             Mobile Phones        Review   Spoken   \n",
       "\n",
       "                      No. Targets (Dataset Size)  No. Senti Labels  \\\n",
       "SemEval 14 Laptop                           2951                 3   \n",
       "SemEval 14 Resturant                        4722                 3   \n",
       "Mitchel                                     3288                 3   \n",
       "Dong Twitter                                6940                 3   \n",
       "Election Twitter                           11899                 3   \n",
       "YouTuBean                                    798                 3   \n",
       "\n",
       "                      Mean Targets per Sent  No Unique Targets  \\\n",
       "SemEval 14 Laptop                      1.58               1295   \n",
       "SemEval 14 Resturant                   1.83               1630   \n",
       "Mitchel                                1.22               2507   \n",
       "Dong Twitter                           1.00                145   \n",
       "Election Twitter                       2.94               2190   \n",
       "YouTuBean                              2.07                522   \n",
       "\n",
       "                      % Targets with 1 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                       81.09   \n",
       "SemEval 14 Resturant                                    75.26   \n",
       "Mitchel                                                 90.48   \n",
       "Dong Twitter                                           100.00   \n",
       "Election Twitter                                        44.50   \n",
       "YouTuBean                                               81.45   \n",
       "\n",
       "                      % Targets with 2 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                       17.62   \n",
       "SemEval 14 Resturant                                    22.94   \n",
       "Mitchel                                                  9.43   \n",
       "Dong Twitter                                             0.00   \n",
       "Election Twitter                                        46.72   \n",
       "YouTuBean                                               18.17   \n",
       "\n",
       "                      % Targets with 3 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                        1.29   \n",
       "SemEval 14 Resturant                                     1.80   \n",
       "Mitchel                                                  0.09   \n",
       "Dong Twitter                                             0.00   \n",
       "Election Twitter                                         8.78   \n",
       "YouTuBean                                                0.38   \n",
       "\n",
       "                      Avg sentence length per target  \n",
       "SemEval 14 Laptop                              18.57  \n",
       "SemEval 14 Resturant                           17.25  \n",
       "Mitchel                                        18.02  \n",
       "Dong Twitter                                   17.37  \n",
       "Election Twitter                               21.68  \n",
       "YouTuBean                                      22.53  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = defaultdict(list)\n",
    "index = []\n",
    "columns = ['Domain', 'Type', 'Medium', 'No. Targets (Dataset Size)', \n",
    "           'No. Senti Labels', 'Mean Targets per Sent', 'No Unique Targets',\n",
    "           '% Targets with 1 Sentiment per Sentence', '% Targets with 2 Sentiment per Sentence', \n",
    "           '% Targets with 3 Sentiment per Sentence', 'Avg sentence length per target']\n",
    "name_domain = {'SemEval 14 Laptop' : 'Laptop', 'SemEval 14 Resturant' : 'Restaurant', \n",
    "               'Mitchel' : 'Unknown', 'Dong Twitter' : 'General', 'Election Twitter' : 'Politics',\n",
    "               'YouTuBean' : 'Mobile Phones'}\n",
    "name_type = {'SemEval 14 Laptop' : 'Review', 'SemEval 14 Resturant' : 'Review', \n",
    "               'Mitchel' : 'Social Media', 'Dong Twitter' : 'Social Media', 'Election Twitter' : 'Social Media',\n",
    "               'YouTuBean' : 'Review'}\n",
    "name_medium = {'SemEval 14 Laptop' : 'Written', 'SemEval 14 Resturant' : 'Written', \n",
    "               'Mitchel' : 'Written', 'Dong Twitter' : 'Written', 'Election Twitter' : 'Written',\n",
    "               'YouTuBean' : 'Spoken'}\n",
    "for name, dataset in datasets.items():\n",
    "    index.append(name)\n",
    "    targets_i_senti = []\n",
    "    num_targets = len(dataset)\n",
    "    num_sentiment_labels = len(dataset.stored_sentiments())\n",
    "    avg_sent_length = dataset.avg_sentence_length_per_target()\n",
    "    for i in range(1, 4):\n",
    "        if i > num_sentiment_labels:\n",
    "            targets_i_senti.append(0)\n",
    "        else:\n",
    "            i_senti_targets = len(dataset.subset_by_sentiment(i))\n",
    "            targets_i_senti\\\n",
    "            .append((i_senti_targets / num_targets) * 100)\n",
    "            \n",
    "    dataset_dict['Domain'].append(name_domain[name])\n",
    "    dataset_dict['Type'].append(name_type[name])\n",
    "    dataset_dict['Medium'].append(name_medium[name])\n",
    "    dataset_dict['No. Targets (Dataset Size)'].append(num_targets)\n",
    "    dataset_dict['No. Senti Labels'].append(num_sentiment_labels)\n",
    "    dataset_dict['Mean Targets per Sent'].append(dataset\\\n",
    "                                                 .avg_targets_per_sentence())\n",
    "    dataset_dict['No Unique Targets'].append(dataset.number_unique_targets())\n",
    "    dataset_dict['% Targets with 1 Sentiment per Sentence'].append(targets_i_senti[0])\n",
    "    dataset_dict['% Targets with 2 Sentiment per Sentence'].append(targets_i_senti[1])\n",
    "    dataset_dict['% Targets with 3 Sentiment per Sentence'].append(targets_i_senti[2])\n",
    "    dataset_dict['Avg sentence length per target'].append(avg_sent_length)\n",
    "    \n",
    "\n",
    "dataset_stats = pd.DataFrame(dataset_dict, index=index, columns=columns)\n",
    "dataset_stats.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high level statistics are presented above. At first it is a surprising that the Social media data has such a high average sentence length but the sentence in the Twitter cases is actually a Tweet compared to the SemEval and YouTuBean data which has been sentence split. However the YouTuBean data even when sentence split is still the longest this could be due to the data being speech text rather than written.\n",
    "\n",
    "Again the datasets vary with the number of Targets with distinct sentiments per sentence but most have only one distinct sentiment per sentence apart from the Election dataset which has quiet an even split between 1 and 2 distinct sentiments.\n",
    "\n",
    "Lastly the Election dataset has the highest number of targets per sentence by a long way and this is not porportinal to the average sentence length either.\n",
    "\n",
    "## Syntactic Complexity of the dataset\n",
    "The above statistics are all based on quiet high level summary statistics and do not contain any lingustic specfic statistic apart from perhaps the average sentence length. Therefore below is the table of average constituency tree depth for the datasets which can be viewed as showing the sentence syntax complexity this was also shown in the [Marrese-Taylor et al.](https://www.aclweb.org/anthology/W17-5213) paper on the datasets they used and here we present the same statistic on all of the datasets above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ling_dict = defaultdict(list)\n",
    "index = []\n",
    "columns = ['Average constituency tree depth']\n",
    "for name, dataset in datasets.items():\n",
    "    index.append(name)\n",
    "    dataset_ling_dict['Average constituency tree depth'].append(dataset.avg_constituency_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average constituency tree depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>10.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Resturant</th>\n",
       "      <td>9.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>11.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Average constituency tree depth\n",
       "SemEval 14 Laptop                               10.61\n",
       "SemEval 14 Resturant                             9.73\n",
       "Mitchel                                          8.28\n",
       "Dong Twitter                                     8.34\n",
       "Election Twitter                                 9.67\n",
       "YouTuBean                                       11.72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ling_stats = pd.DataFrame(dataset_ling_dict, index=index, columns=columns)\n",
    "dataset_ling_stats.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above interestingly the Election dataset that had the 2nd largest average sentence length and by far the largest number of targets per sentence but does not have the largest average tree depth. The YouTuBean dataset does which may suggest that spoken text is syntactically more complex then written text. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
